BootStrap: docker
From: nvidia/cuda:12.4.0-devel-ubuntu22.04

%environment
    # matches common transformer env usage
    export TOKENIZERS_PARALLELISM=false
    export PYTHONUNBUFFERED=1

%files
    requirements_tuner.txt /opt/requirements_tuner.txt

%post
    set -eux

    export TMPDIR=/var/tmp
    mkdir -p "$TMPDIR" /tmp
    chmod 1777 "$TMPDIR" /tmp

    export APT_CACHE="$TMPDIR/apt-cache"
    export APT_LISTS="$TMPDIR/apt-lists"
    mkdir -p "$APT_CACHE/archives/partial" "$APT_LISTS/partial"

    apt-get \
      -o Dir::Tmp="$TMPDIR" \
      -o Dir::Cache="$APT_CACHE" \
      -o Dir::Cache::archives="$APT_CACHE/archives" \
      -o Dir::State::lists="$APT_LISTS" \
      update

    DEBIAN_FRONTEND=noninteractive apt-get \
      -o Dir::Tmp="$TMPDIR" \
      -o Dir::Cache="$APT_CACHE" \
      -o Dir::Cache::archives="$APT_CACHE/archives" \
      -o Dir::State::lists="$APT_LISTS" \
      install -y --no-install-recommends \
        python3 python3-pip python3-venv python3-dev \
        git ca-certificates curl \
        build-essential ninja-build pkg-config libssl-dev

    python3 -m pip install --upgrade pip setuptools wheel packaging ninja psutil

    # Install CUDA-enabled PyTorch (uses the official PyTorch CUDA wheel index for cu124)
    # This ensures torch is the CUDA build before we install flash-attn.
    python3 -m pip install --no-cache-dir \
        torch torchvision torchaudio \
        --index-url https://download.pytorch.org/whl/cu124

    python3 -m pip install --no-cache-dir -r /opt/requirements_tuner.txt

    python3 -m pip install --no-cache-dir flash-attn --no-build-isolation

    rm -rf "$APT_LISTS"/*


%runscript
    cd /app
    exec python3 main.py --tune
