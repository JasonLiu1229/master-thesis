BootStrap: docker
From: nvidia/cuda:12.4.0-devel-ubuntu22.04

%environment
    # matches common transformer env usage
    export TOKENIZERS_PARALLELISM=false
    export PYTHONUNBUFFERED=1

%files
    requirements_tuner.txt /opt/requirements_tuner.txt

%post
    set -eux

    export TMPDIR=/var/tmp
    mkdir -p "$TMPDIR" /tmp
    chmod 1777 "$TMPDIR" /tmp

    apt-get -o Dir::Tmp=/var/tmp update
    DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
        python3 \
        python3-pip \
        python3-venv \
        python3-dev \
        git \
        ca-certificates \
        curl \
        build-essential \
        ninja-build \
        pkg-config \
        libssl-dev \
        && rm -rf /var/lib/apt/lists/*

    python3 -m pip install --upgrade pip setuptools wheel packaging ninja psutil

    # Install CUDA-enabled PyTorch (uses the official PyTorch CUDA wheel index for cu124)
    # This ensures torch is the CUDA build before we install flash-attn.
    python3 -m pip install --no-cache-dir \
        torch torchvision torchaudio \
        --index-url https://download.pytorch.org/whl/cu124

    python3 -m pip install --no-cache-dir -r /opt/requirements_tuner.txt

    python3 -m pip install --no-cache-dir flash-attn --no-build-isolation

%runscript
    cd /app
    exec python3 main.py --tune
